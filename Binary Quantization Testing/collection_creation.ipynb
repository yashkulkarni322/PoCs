{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53da6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# List your textbook PDF file paths here\n",
    "pdf_files = [\"C:\\\\Users\\\\prask\\\\OneDrive\\\\Desktop\\\\Internship\\\\Binary Quantization Testing\\\\level-4-Crime-Story-Penguin-Readers-1.pdf\"]\n",
    "\n",
    "# Extract text from each textbook\n",
    "texts = []\n",
    "for file in pdf_files:\n",
    "    text = extract_text(file)\n",
    "    texts.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad26bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 83\n",
      "Crime Story Collection \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Level 4 \n",
      " \n",
      "Retold by John and Celia Turvey                                                \n",
      "Series Editors: Andy Hopkins and Jocelyn Potter \n",
      "Pearson Education limited \n",
      "Edinburgh Gate, Harlow, \n",
      "Essex CM20 2JE, England \n",
      "and Associated Companies throughout the world. \n",
      "ISBN 0 582 419190 \n",
      " \n",
      "This compilation first published in Longman Fiction 1998                                                        \n",
      "This edition first published 1999 \n",
      "NEW  EDITION \n",
      " \n",
      "5 7 9 10 8 6 \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Assuming 'texts' is a list of strings, each containing the extracted text from a textbook\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2048,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "all_chunks = []\n",
    "for text in texts:\n",
    "    chunks = splitter.split_text(text)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "print(f\"Total number of chunks: {len(all_chunks)}\")\n",
    "# Optional: Inspect the first chunk\n",
    "print(all_chunks[0][:500])  # Print first 500 characters of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a9173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "JINA_API_KEY = \"JINA_API_KEY\"  # Replace with your actual API key\n",
    "endpoint = \"https://api.jina.ai/v1/embeddings\"\n",
    "\n",
    "def get_jina_embeddings(texts, dimensions=1024, task=\"retrieval.passage\"):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {JINA_API_KEY}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"input\": texts,\n",
    "        \"model\": \"jina-embeddings-v3\",\n",
    "        \"dimensions\": dimensions,\n",
    "        \"task\": task\n",
    "    }\n",
    "    response = requests.post(endpoint, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return [item[\"embedding\"] for item in response.json()[\"data\"]]\n",
    "\n",
    "# Example: batch your chunks to avoid API limits\n",
    "batch_size = 32\n",
    "dense_embeddings = []\n",
    "for i in range(0, len(all_chunks), batch_size):\n",
    "    batch = all_chunks[i:i+batch_size]\n",
    "    dense_embeddings.extend(get_jina_embeddings(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce7cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import SparseTextEmbedding\n",
    "\n",
    "# Replace all_chunks with your list of text chunks\n",
    "model = SparseTextEmbedding(model_name=\"Qdrant/bm25\")\n",
    "sparse_embeddings = list(model.embed(all_chunks))\n",
    "# Example: Get indices and values for the first chunk\n",
    "indices = sparse_embeddings[0].indices\n",
    "values = sparse_embeddings[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd7ab7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = [\n",
    "    {\"indices\": emb.indices, \"values\": emb.values}\n",
    "    for emb in sparse_embeddings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f65e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'finance_docs' already exists.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(host=\"192.168.1.13\", port=6333)\n",
    "\n",
    "collection_name = \"With_BQ\"\n",
    "\n",
    "try:\n",
    "    client.get_collection(collection_name)\n",
    "    print(f\"Collection '{collection_name}' already exists.\")\n",
    "except Exception:\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={\n",
    "            \"dense\": models.VectorParams(\n",
    "                size=1024,\n",
    "                distance=models.Distance.COSINE,\n",
    "            ),\n",
    "        },\n",
    "        sparse_vectors_config={\n",
    "            \"sparse\": models.SparseVectorParams()\n",
    "        },\n",
    "        shard_number=1,\n",
    "    )\n",
    "    print(f\"Collection '{collection_name}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a049cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Connect to your Qdrant instance\n",
    "client = QdrantClient(host=\"192.168.1.13\", port=6333)\n",
    "\n",
    "def ensure_sparse_dict(sparse_emb):\n",
    "    \"\"\"\n",
    "    Converts a sparse embedding to Qdrant's expected dict format.\n",
    "    \"\"\"\n",
    "    if isinstance(sparse_emb, dict):\n",
    "        return sparse_emb\n",
    "    elif hasattr(sparse_emb, \"indices\") and hasattr(sparse_emb, \"values\"):\n",
    "        return {\"indices\": list(sparse_emb.indices), \"values\": list(sparse_emb.values)}\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sparse embedding format: {type(sparse_emb)}\")\n",
    "\n",
    "# Prepare points for upsert\n",
    "points = []\n",
    "for idx, (text, dense_emb, sparse_emb) in enumerate(zip(all_chunks, dense_embeddings, sparse_embeddings)):\n",
    "    dense_emb_list = dense_emb.tolist() if hasattr(dense_emb, \"tolist\") else dense_emb\n",
    "    sparse_emb_dict = ensure_sparse_dict(sparse_emb)\n",
    "    points.append({\n",
    "        \"id\": idx,\n",
    "        \"vector\": {\n",
    "            \"dense\": dense_emb_list,\n",
    "            \"sparse\": sparse_emb_dict\n",
    "        },\n",
    "        \"payload\": {\"text\": text}\n",
    "    })\n",
    "\n",
    "# Upsert points in batches for efficiency\n",
    "batch_size = 256\n",
    "for i in range(0, len(points), batch_size):\n",
    "    batch = points[i:i+batch_size]\n",
    "    client.upsert(collection_name=\"With_BQ\", points=batch)\n",
    "    print(f\"Upserted points {i} to {i+len(batch)-1}\")\n",
    "\n",
    "print(f\"Inserted {len(points)} points into collection 'test'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "060594a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "collection_name = \"With_BQ\"  # Replace with your actual collection name\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=\"http://192.168.1.13:6333\"\n",
    ")\n",
    "\n",
    "# Update collection configuration\n",
    "client.update_collection(\n",
    "    collection_name=collection_name,\n",
    "    hnsw_config=models.HnswConfigDiff(\n",
    "        m=32,\n",
    "        ef_construct=200,\n",
    "    ),\n",
    "    quantization_config=models.BinaryQuantization(\n",
    "        binary=models.BinaryQuantizationConfig(always_ram=True),\n",
    "    ),\n",
    ")\n",
    "\n",
    "search_params = models.SearchParams(\n",
    "    quantization=models.QuantizationSearchParams(\n",
    "        ignore=False,\n",
    "        rescore=True,\n",
    "        oversampling=2.0,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
